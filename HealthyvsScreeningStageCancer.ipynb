{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2193, 351)\n",
      "0                  healthy\n",
      "1                  healthy\n",
      "2                  healthy\n",
      "3                  healthy\n",
      "4                  healthy\n",
      "               ...        \n",
      "2188    early stage cancer\n",
      "2189    early stage cancer\n",
      "2190    early stage cancer\n",
      "2191    early stage cancer\n",
      "2192    early stage cancer\n",
      "Name: class_label, Length: 2193, dtype: object\n",
      "class_label\n",
      "early stage cancer        781\n",
      "screening stage cancer    490\n",
      "mid stage cancer          453\n",
      "late stage cancer         409\n",
      "healthy                    60\n",
      "Name: count, dtype: int64\n",
      "Shape of filtered data: (550, 351)\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q * linpred)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(yvals_binary\u001b[38;5;241m.\u001b[39munique()) \u001b[38;5;66;03m# double confirm correct conversion of the y values \u001b[39;00m\n\u001b[1;32m     44\u001b[0m logit_model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mLogit(yvals_binary, x_std) \u001b[38;5;66;03m# carry out logistic regression\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlogit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39msummary()) \u001b[38;5;66;03m# summary of model\u001b[39;00m\n\u001b[1;32m     47\u001b[0m p_values \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mpvalues \u001b[38;5;66;03m# obtain p values of regressor features in model\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2601\u001b[0m, in \u001b[0;36mLogit.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(DiscreteModel\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m,\n\u001b[1;32m   2600\u001b[0m         full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2601\u001b[0m     bnryfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2609\u001b[0m     discretefit \u001b[38;5;241m=\u001b[39m LogitResults(\u001b[38;5;28mself\u001b[39m, bnryfit)\n\u001b[1;32m   2610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:243\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/base/model.py:582\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m cov_params_func(\u001b[38;5;28mself\u001b[39m, xopt, retvals)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m full_output:\n\u001b[0;32m--> 582\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mretvals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHessian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hessian:\n\u001b[1;32m    584\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhessian(xopt)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "### Healthy vs Screening Stage Cancer (comparison method)\n",
    "\n",
    "### Preprocessing for cancer vs screening stage cancer\n",
    "\n",
    "### Import Libraries\n",
    "import os # importing operating system library\n",
    "import numpy as np # importing numpy library\n",
    "import pandas as pd # importing pandas library\n",
    "import matplotlib as mp # importing matplotlib library\n",
    "import statsmodels.api as sm # importing statsmodels library\n",
    "\n",
    "# ### Access directory\n",
    "# os.getcwd()\n",
    "# os.chdir('/Users/tech26/Desktop/NUS/ACADEMICS/Y1S2/IT1244/Project/Code/IT1244-Final-Project') # change directory as neccesary\n",
    "\n",
    "### Read Data / Visualise\n",
    "trainp_data = pd.read_csv('Train_Set.csv') # access training data\n",
    "trainp_data.head(5) # information on first five data points\n",
    "print(trainp_data.shape) # dimensions of data set\n",
    "trainp_data.describe() # statistical information on data set\n",
    "trainp_data.isna().sum() # check how many data points missing\n",
    "print(trainp_data.iloc[:, -1]) # view response variable (status of cancer)\n",
    "print(trainp_data['class_label'].value_counts()) # distribution of response variable (status of cancer)\n",
    "\n",
    "### Remove classes that are not either healthy or screening stage cancer\n",
    "trainp_data = trainp_data[(trainp_data['class_label'] == 'healthy') | (trainp_data['class_label'] == 'screening stage cancer')] # remove non he;lathy and non screening stage cancer classes\n",
    "trainp_data.reset_index(drop=True, inplace=True)\n",
    "print(\"Shape of filtered data:\", trainp_data.shape)\n",
    "\n",
    "### Initialise x and y variables \n",
    "xvals = trainp_data.iloc[:, 0:350] # access x values\n",
    "yvals = trainp_data.iloc[:,350] # access y values\n",
    "\n",
    "### Standardising x values\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "std_x = StandardScaler() # initialise StandardScaler\n",
    "x_std = std_x.fit_transform(xvals) # standardise x values\n",
    "\n",
    "### Techniques to remove regressors\n",
    "\n",
    "### Perform logistic regression to identify insignifcant regressors based on p value\n",
    "yvals_binary = yvals.map({'screening stage cancer': 1, 'healthy': 0}) # Convert \"screening stage cancer\" to 1 and \"healthy\" to 0\n",
    "print(yvals_binary.unique()) # double confirm correct conversion of the y values \n",
    "logit_model = sm.Logit(yvals_binary, x_std) # carry out logistic regression\n",
    "result = logit_model.fit()\n",
    "print(result.summary()) # summary of model\n",
    "p_values = result.pvalues # obtain p values of regressor features in model\n",
    "significant_features_1 = list(p_values[p_values < 0.05].index.tolist()) # Filter out significant features with p-value < 0.05\n",
    "insignificant_features_1 = list(p_values[p_values > 0.05].index.tolist()) # Filter out insignificant features with p-value > 0.05\n",
    "\n",
    "### Perform L1 (lasso) regularisation to logistic regression model to idenitify insignifcant regressors with coefficients zero\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg_l1 = LogisticRegression(penalty='l1', solver='liblinear')  # specify solver for L1 regularization\n",
    "log_reg_l1.fit(x_std, yvals_binary)  # train model\n",
    "significant_features_2 = list(xvals.columns[log_reg_l1.coef_[0] != 0]) # check if there are any signifcant features identified\n",
    "insignificant_features_2 = list(xvals.columns[log_reg_l1.coef_[0] == 0]) # identify insignifcant features\n",
    "\n",
    "### Perform principal component analysis to identify insignifcant regressors that contrivbute little to variance\n",
    "from sklearn.decomposition import PCA \n",
    "pca = PCA() # initialise PCA with default parameters\n",
    "x_pca = pca.fit_transform(x_std) # compute principal components and transforms data into new feature space\n",
    "explained_variance_ratio = pca.explained_variance_ratio_  # Get explained variance ratio for each component\n",
    "cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio) # sum computed variance for certain number of components\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cumulative_explained_variance_ratio) # plot cumulative explained variance ratio\n",
    "plt.grid(True) # add grid to the plot\n",
    "plt.show() # show graph\n",
    "\n",
    "chosen_num_components = 25  # plateu cannot be read accurately so limit x axis to [0,25] and plot again\n",
    "plt.plot(range(1, chosen_num_components + 1), cumulative_explained_variance_ratio[:chosen_num_components])\n",
    "plt.grid(True) # add grid to the plot\n",
    "plt.show() # plateu can be read \n",
    "\n",
    "chosen_num_components = 3 # there is little to no change in cumulative variance when more than 3 principal components are involved in calculations\n",
    "pca = PCA(n_components = chosen_num_components) # initialise new pca with no of components = 3\n",
    "x_pca = pca.fit_transform(x_std) # compute principal components and transforms data into new feature space\n",
    "\n",
    "original_features = xvals.columns # all features\n",
    "significant_feature_indices = np.where(cumulative_explained_variance_ratio <= 0.95)[0] # identify festures that are responsible for 95 oercent of variance\n",
    "significant_features_3 = list(original_features[significant_feature_indices])\n",
    "insignificant_feature_indices = np.where(cumulative_explained_variance_ratio > 0.95)[0]\n",
    "insignificant_features_3 = list(original_features[insignificant_feature_indices])\n",
    "\n",
    "### Perform correlation analysis to identify insignifcant regressors that are are highly correlated\n",
    "correlation_matrix = xvals.corr() # find correlation coefficients between each pair of variables\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool)) # mask to consider only the upper triangular matrix and ignore correlation between the same variable. Output is true and false\n",
    "correlation_matrix = correlation_matrix.mask(mask) # apply mask to correlation matrix\n",
    "significant_features_4 = list(xvals.columns)\n",
    "insignificant_features_4 = []\n",
    " \n",
    "for i in range(len(correlation_matrix.columns)): # Loop through the columnns\n",
    "    for j in range(i): # Loop through the rows\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:  # Adjust the threshold as needed. Set 0.8 here\n",
    "            colname_i = correlation_matrix.columns[i] # first compared feature\n",
    "            colname_j = correlation_matrix.columns[j] # second compared feature\n",
    "            if colname_i in significant_features_4:\n",
    "                significant_features_4.remove(colname_i) # update the significant features\n",
    "            if colname_i not in insignificant_features_4:\n",
    "                insignificant_features_4.append(colname_i) # update the siugnifcant features\n",
    "\n",
    "### Decide which features to remove\n",
    "\n",
    "### check lengths of features to be removed\n",
    "removables = {}\n",
    "for feature in insignificant_features_1:\n",
    "    if feature not in removables:\n",
    "        removables[feature] = 0\n",
    "    removables[feature] += 1\n",
    "\n",
    "for feature in insignificant_features_2:\n",
    "    if feature not in removables:\n",
    "        removables[feature] = 0\n",
    "    removables[feature] += 1\n",
    "\n",
    "for feature in insignificant_features_3:\n",
    "    if feature not in removables:\n",
    "        removables[feature] = 0\n",
    "    removables[feature] += 1\n",
    "\n",
    "for feature in insignificant_features_4:\n",
    "    if feature not in removables:\n",
    "        removables[feature] = 0\n",
    "    removables[feature] += 1\n",
    "\n",
    "len(xvals.columns) # no of features in\\ dataset \n",
    "\n",
    "drops_2 = []\n",
    "for feature in removables:\n",
    "    if removables[feature] >= 2:\n",
    "        drops_2.append(feature)\n",
    "len(drops_2) # 349 variables removed # 1 variables preserved\n",
    "\n",
    "drops_3 = []\n",
    "for feature in removables:\n",
    "    if removables[feature] >= 3:\n",
    "        drops_3.append(feature)\n",
    "len(drops_3) # 333 variables removed # 17 variables preserved\n",
    "\n",
    "drops_4 = []\n",
    "for feature in removables:\n",
    "    if removables[feature] >= 4:\n",
    "        drops_4.append(feature)\n",
    "len(drops_4) # 0 variables remnoved # 350 variables preserved \n",
    "\n",
    "### drops_3 selected to prevent underfitting or overfitting of the model\n",
    "xvals_filtered = xvals.drop(columns=drops_3)\n",
    "xvals_filtered.shape\n",
    "\n",
    "# xvals_filtered to be used as dependent variables used to build the model\n",
    "# yvals to be used as the response variable used to build the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
