{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing for Screening Stage Cancer vs healthy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import operating system, numpy, pandas, matplotlib, statsmodels, random libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mp \n",
    "import statsmodels.api as sm \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed to ensure reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read train and test data and visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   length_51  length_52  length_53  length_54  length_55  length_56  \\\n",
      "0   0.000152   0.000081   0.000087   0.000092   0.000099   0.000125   \n",
      "1   0.006256   0.006413   0.006512   0.006469   0.006810   0.007070   \n",
      "2   0.003783   0.003886   0.004063   0.004237   0.004481   0.004832   \n",
      "3   0.004635   0.004471   0.004383   0.004829   0.004920   0.005056   \n",
      "4   0.011315   0.010045   0.009795   0.009906   0.010630   0.011467   \n",
      "\n",
      "   length_57  length_58  length_59  length_60  ...  length_392  length_393  \\\n",
      "0   0.000122   0.000115   0.000151   0.000167  ...    0.007396    0.007193   \n",
      "1   0.007748   0.008088   0.008671   0.008835  ...    0.017830    0.017033   \n",
      "2   0.004960   0.005605   0.005919   0.006480  ...    0.010957    0.010481   \n",
      "3   0.005475   0.006158   0.007174   0.007697  ...    0.010032    0.008933   \n",
      "4   0.013024   0.014853   0.016874   0.017501  ...    0.009118    0.008535   \n",
      "\n",
      "   length_394  length_395  length_396  length_397  length_398  length_399  \\\n",
      "0    0.006973    0.006481    0.006139    0.005958    0.005578    0.005327   \n",
      "1    0.016373    0.015371    0.014340    0.013975    0.013243    0.012725   \n",
      "2    0.009782    0.009211    0.008800    0.008320    0.007869    0.007286   \n",
      "3    0.008970    0.008546    0.008125    0.007587    0.007501    0.006931   \n",
      "4    0.008233    0.007754    0.007584    0.006933    0.006530    0.006378   \n",
      "\n",
      "   length_400  class_label  \n",
      "0    0.005142      healthy  \n",
      "1    0.012267      healthy  \n",
      "2    0.007020      healthy  \n",
      "3    0.006663      healthy  \n",
      "4    0.005842      healthy  \n",
      "\n",
      "[5 rows x 351 columns]\n",
      "   length_51  length_52  length_53  length_54  length_55  length_56  \\\n",
      "0   0.005657   0.005277   0.005162   0.005267   0.005287   0.005824   \n",
      "1   0.005132   0.004886   0.004952   0.005123   0.005237   0.005530   \n",
      "2   0.006114   0.005463   0.005444   0.005369   0.005425   0.005897   \n",
      "3   0.000158   0.000089   0.000085   0.000097   0.000107   0.000142   \n",
      "4   0.000215   0.000116   0.000129   0.000144   0.000160   0.000186   \n",
      "\n",
      "   length_57  length_58  length_59  length_60  ...  length_392  length_393  \\\n",
      "0   0.006033   0.006759   0.007641   0.008071  ...    0.015585    0.014792   \n",
      "1   0.006147   0.006655   0.007607   0.008042  ...    0.010007    0.009324   \n",
      "2   0.006341   0.007238   0.008696   0.008772  ...    0.019935    0.018711   \n",
      "3   0.000141   0.000184   0.000206   0.000189  ...    0.006689    0.006362   \n",
      "4   0.000224   0.000226   0.000345   0.000321  ...    0.004744    0.004640   \n",
      "\n",
      "   length_394  length_395  length_396  length_397  length_398  length_399  \\\n",
      "0    0.013918    0.013191    0.012644    0.011750    0.011413    0.011053   \n",
      "1    0.009207    0.008628    0.008210    0.007823    0.007412    0.007054   \n",
      "2    0.017700    0.017124    0.016344    0.015406    0.014876    0.014111   \n",
      "3    0.006070    0.005884    0.005488    0.005127    0.004942    0.004801   \n",
      "4    0.004561    0.004232    0.003967    0.003795    0.003561    0.003568   \n",
      "\n",
      "   length_400  class_label  \n",
      "0    0.010341      healthy  \n",
      "1    0.006992      healthy  \n",
      "2    0.013640      healthy  \n",
      "3    0.004483      healthy  \n",
      "4    0.003286      healthy  \n",
      "\n",
      "[5 rows x 351 columns]\n",
      "(2193, 351)\n",
      "(1034, 351)\n",
      "         length_51    length_52    length_53    length_54    length_55  \\\n",
      "count  2193.000000  2193.000000  2193.000000  2193.000000  2193.000000   \n",
      "mean      0.006481     0.006008     0.005988     0.006060     0.006290   \n",
      "std       0.006746     0.006086     0.006054     0.005993     0.006205   \n",
      "min       0.000032     0.000030     0.000022     0.000027     0.000040   \n",
      "25%       0.001378     0.001273     0.001326     0.001387     0.001523   \n",
      "50%       0.005429     0.005047     0.005021     0.005203     0.005286   \n",
      "75%       0.009495     0.008846     0.008716     0.008813     0.009160   \n",
      "max       0.079471     0.069445     0.069445     0.067825     0.071855   \n",
      "\n",
      "         length_56    length_57    length_58    length_59    length_60  ...  \\\n",
      "count  2193.000000  2193.000000  2193.000000  2193.000000  2193.000000  ...   \n",
      "mean      0.006771     0.007466     0.008759     0.010395     0.011411  ...   \n",
      "std       0.006739     0.007542     0.009192     0.011396     0.012763  ...   \n",
      "min       0.000038     0.000040     0.000051     0.000049     0.000087  ...   \n",
      "25%       0.001646     0.001867     0.002260     0.002737     0.003024  ...   \n",
      "50%       0.005657     0.006068     0.006904     0.007943     0.008646  ...   \n",
      "75%       0.009723     0.010538     0.012197     0.013973     0.014923  ...   \n",
      "max       0.078914     0.091267     0.113398     0.140649     0.157588  ...   \n",
      "\n",
      "        length_391   length_392   length_393   length_394   length_395  \\\n",
      "count  2193.000000  2193.000000  2193.000000  2193.000000  2193.000000   \n",
      "mean      0.012359     0.011886     0.011411     0.010904     0.010408   \n",
      "std       0.008149     0.007805     0.007517     0.007135     0.006833   \n",
      "min       0.002320     0.002242     0.002067     0.002086     0.001965   \n",
      "25%       0.007085     0.006759     0.006528     0.006232     0.005922   \n",
      "50%       0.010115     0.009691     0.009214     0.008894     0.008412   \n",
      "75%       0.015154     0.014573     0.014064     0.013267     0.012660   \n",
      "max       0.062695     0.061578     0.060024     0.058549     0.056764   \n",
      "\n",
      "        length_396   length_397   length_398   length_399   length_400  \n",
      "count  2193.000000  2193.000000  2193.000000  2193.000000  2193.000000  \n",
      "mean      0.009958     0.009503     0.009131     0.008747     0.008415  \n",
      "std       0.006561     0.006235     0.006017     0.005747     0.005516  \n",
      "min       0.001843     0.001731     0.001698     0.001659     0.001567  \n",
      "25%       0.005651     0.005429     0.005268     0.005047     0.004868  \n",
      "50%       0.008024     0.007695     0.007378     0.007011     0.006708  \n",
      "75%       0.012156     0.011621     0.011155     0.010666     0.010283  \n",
      "max       0.055813     0.054001     0.052768     0.051798     0.049086  \n",
      "\n",
      "[8 rows x 350 columns]\n",
      "         length_51    length_52    length_53    length_54    length_55  \\\n",
      "count  1034.000000  1034.000000  1034.000000  1034.000000  1034.000000   \n",
      "mean      0.008011     0.007394     0.007398     0.007488     0.007869   \n",
      "std       0.008406     0.007525     0.007509     0.007483     0.007873   \n",
      "min       0.000025     0.000036     0.000023     0.000033     0.000036   \n",
      "25%       0.001941     0.001862     0.001862     0.001946     0.002111   \n",
      "50%       0.005219     0.004891     0.004954     0.005130     0.005282   \n",
      "75%       0.011696     0.010996     0.010919     0.011181     0.011558   \n",
      "max       0.057527     0.050626     0.050988     0.051242     0.053144   \n",
      "\n",
      "         length_56    length_57    length_58    length_59    length_60  ...  \\\n",
      "count  1034.000000  1034.000000  1034.000000  1034.000000  1034.000000  ...   \n",
      "mean      0.008487     0.009376     0.011120     0.013354     0.014610  ...   \n",
      "std       0.008597     0.009672     0.011985     0.015066     0.016892  ...   \n",
      "min       0.000035     0.000045     0.000046     0.000056     0.000084  ...   \n",
      "25%       0.002335     0.002632     0.003197     0.003842     0.004202  ...   \n",
      "50%       0.005617     0.006081     0.006860     0.008070     0.008703  ...   \n",
      "75%       0.012455     0.013728     0.015606     0.018253     0.019891  ...   \n",
      "max       0.059801     0.067901     0.085847     0.108628     0.121494  ...   \n",
      "\n",
      "        length_391   length_392   length_393   length_394   length_395  \\\n",
      "count  1034.000000  1034.000000  1034.000000  1034.000000  1034.000000   \n",
      "mean      0.012319     0.011851     0.011405     0.010898     0.010456   \n",
      "std       0.005852     0.005697     0.005485     0.005271     0.005134   \n",
      "min       0.003934     0.003707     0.003543     0.003326     0.003265   \n",
      "25%       0.008016     0.007652     0.007377     0.007021     0.006612   \n",
      "50%       0.011963     0.011609     0.011134     0.010668     0.010147   \n",
      "75%       0.014639     0.014084     0.013623     0.013069     0.012379   \n",
      "max       0.046973     0.046223     0.044458     0.043484     0.043309   \n",
      "\n",
      "        length_396   length_397   length_398   length_399   length_400  \n",
      "count  1034.000000  1034.000000  1034.000000  1034.000000  1034.000000  \n",
      "mean      0.009974     0.009547     0.009152     0.008837     0.008510  \n",
      "std       0.004931     0.004724     0.004598     0.004443     0.004318  \n",
      "min       0.003119     0.002938     0.002679     0.002644     0.002565  \n",
      "25%       0.006304     0.006076     0.005790     0.005621     0.005401  \n",
      "50%       0.009676     0.009325     0.008831     0.008552     0.008268  \n",
      "75%       0.011935     0.011368     0.010904     0.010568     0.010201  \n",
      "max       0.042769     0.041197     0.040434     0.039729     0.038730  \n",
      "\n",
      "[8 rows x 350 columns]\n"
     ]
    }
   ],
   "source": [
    "trainp_data = pd.read_csv('Train_Set.csv')\n",
    "testp_data = pd.read_csv('Test_Set.csv')\n",
    "print(trainp_data.head(5)) # information on first five data points\n",
    "print(testp_data.head(5)) # information on first five data points\n",
    "print(trainp_data.shape) # dimensions of train data set\n",
    "print(testp_data.shape) # dimensions of test data set\n",
    "print(trainp_data.describe()) # statistical information on train data set\n",
    "print(testp_data.describe()) # statistical information on test data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing data points in train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_51      0\n",
      "length_52      0\n",
      "length_53      0\n",
      "length_54      0\n",
      "length_55      0\n",
      "              ..\n",
      "length_397     0\n",
      "length_398     0\n",
      "length_399     0\n",
      "length_400     0\n",
      "class_label    0\n",
      "Length: 351, dtype: int64\n",
      "0                  healthy\n",
      "1                  healthy\n",
      "2                  healthy\n",
      "3                  healthy\n",
      "4                  healthy\n",
      "               ...        \n",
      "2188    early stage cancer\n",
      "2189    early stage cancer\n",
      "2190    early stage cancer\n",
      "2191    early stage cancer\n",
      "2192    early stage cancer\n",
      "Name: class_label, Length: 2193, dtype: object\n",
      "class_label\n",
      "early stage cancer        781\n",
      "screening stage cancer    490\n",
      "mid stage cancer          453\n",
      "late stage cancer         409\n",
      "healthy                    60\n",
      "Name: count, dtype: int64\n",
      "length_51      0\n",
      "length_52      0\n",
      "length_53      0\n",
      "length_54      0\n",
      "length_55      0\n",
      "              ..\n",
      "length_397     0\n",
      "length_398     0\n",
      "length_399     0\n",
      "length_400     0\n",
      "class_label    0\n",
      "Length: 351, dtype: int64\n",
      "0                 healthy\n",
      "1                 healthy\n",
      "2                 healthy\n",
      "3                 healthy\n",
      "4                 healthy\n",
      "              ...        \n",
      "1029    late stage cancer\n",
      "1030    late stage cancer\n",
      "1031    late stage cancer\n",
      "1032    late stage cancer\n",
      "1033    late stage cancer\n",
      "Name: class_label, Length: 1034, dtype: object\n",
      "class_label\n",
      "early stage cancer        368\n",
      "screening stage cancer    230\n",
      "mid stage cancer          206\n",
      "late stage cancer         189\n",
      "healthy                    41\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(trainp_data.isna().sum()) # check how many data points missing\n",
    "print(trainp_data.iloc[:, -1]) # view response variable (status of cancer)\n",
    "print(trainp_data['class_label'].value_counts()) # distribution of response variable (status of cancer)\n",
    "print(testp_data.isna().sum()) # check how many data points missing\n",
    "print(testp_data.iloc[:, -1]) # view response variable (status of cancer)\n",
    "print(testp_data['class_label'].value_counts()) # distribution of response variable (status of cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove irrelevant classes from train and test data that are not either healthy or screening stage cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label\n",
      "screening stage cancer    490\n",
      "healthy                    60\n",
      "Name: count, dtype: int64\n",
      "class_label\n",
      "screening stage cancer    100\n",
      "healthy                    46\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/l997zpqn1n71_t9f81b1qxv00000gn/T/ipykernel_10166/909148494.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  testp_data = trainp_data[(testp_data['class_label'] == 'healthy') |\n"
     ]
    }
   ],
   "source": [
    "trainp_data = trainp_data[(trainp_data['class_label'] == 'healthy') | (trainp_data['class_label'] == 'screening stage cancer')] # remove non he;lathy and non screening stage cancer classes\n",
    "trainp_data.reset_index(drop=True, inplace=True)\n",
    "print(trainp_data['class_label'].value_counts()) \n",
    "testp_data = trainp_data[(testp_data['class_label'] == 'healthy') | \n",
    "(testp_data['class_label'] == 'screening stage cancer')] # remove non he;lathy and non screening stage cancer classes\n",
    "testp_data.reset_index(drop=True, inplace=True)\n",
    "print(testp_data['class_label'].value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise x and y variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals_train = trainp_data.iloc[:, 0:350] # access train x values\n",
    "yvals_train = trainp_data.iloc[:,350] # access train y values\n",
    "xvals_test = testp_data.iloc[:, 0:350] # access test x values\n",
    "yvals_test = testp_data.iloc[:, 350] # access test x values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardising x values in train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "std_x = StandardScaler() # initialise StandardScaler\n",
    "x_std = std_x.fit_transform(xvals_train) # standardise x values\n",
    "x_test_std = std_x.fit_transform(xvals_test) # standardise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technique to remove regressors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform logistic regression to identify insignifcant regressors based on p value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvals_binary = yvals_train.map({'screening stage cancer': 1, 'healthy': 0}) # Convert \"screening stage cancer\" to 1 and \"healthy\" to 0\n",
    "print(yvals_binary.unique()) \n",
    "logit_model = sm.Logit(yvals_binary, x_std) # carry out logistic regression\n",
    "result = logit_model.fit()\n",
    "p_values = result.pvalues # obtain p values of regressor features in model\n",
    "significant_features_1 = list(p_values[p_values < 0.05].index.tolist()) # Filter out significant features with p-value < 0.05\n",
    "insignificant_features_1 = list(p_values[p_values > 0.05].index.tolist()) # Filter out insignificant features with p-value > 0.05\n",
    "print(len(insignificant_features_1) + len(significant_features_1))\n",
    "print(insignificant_features_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2193, 351)\n",
      "0                  healthy\n",
      "1                  healthy\n",
      "2                  healthy\n",
      "3                  healthy\n",
      "4                  healthy\n",
      "               ...        \n",
      "2188    early stage cancer\n",
      "2189    early stage cancer\n",
      "2190    early stage cancer\n",
      "2191    early stage cancer\n",
      "2192    early stage cancer\n",
      "Name: class_label, Length: 2193, dtype: object\n",
      "class_label\n",
      "early stage cancer        781\n",
      "screening stage cancer    490\n",
      "mid stage cancer          453\n",
      "late stage cancer         409\n",
      "healthy                    60\n",
      "Name: count, dtype: int64\n",
      "Shape of filtered data: (550, 351)\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q * linpred)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(yvals_binary\u001b[38;5;241m.\u001b[39munique()) \u001b[38;5;66;03m# double confirm correct conversion of the y values \u001b[39;00m\n\u001b[1;32m     44\u001b[0m logit_model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mLogit(yvals_binary, x_std) \u001b[38;5;66;03m# carry out logistic regression\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlogit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39msummary()) \u001b[38;5;66;03m# summary of model\u001b[39;00m\n\u001b[1;32m     47\u001b[0m p_values \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mpvalues \u001b[38;5;66;03m# obtain p values of regressor features in model\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2601\u001b[0m, in \u001b[0;36mLogit.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(DiscreteModel\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m,\n\u001b[1;32m   2600\u001b[0m         full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2601\u001b[0m     bnryfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2609\u001b[0m     discretefit \u001b[38;5;241m=\u001b[39m LogitResults(\u001b[38;5;28mself\u001b[39m, bnryfit)\n\u001b[1;32m   2610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:243\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/base/model.py:582\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m cov_params_func(\u001b[38;5;28mself\u001b[39m, xopt, retvals)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m full_output:\n\u001b[0;32m--> 582\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mretvals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHessian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hessian:\n\u001b[1;32m    584\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhessian(xopt)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/linalg/linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "\n",
    "### Perform logistic regression to identify insignifcant regressors based on p value\n",
    "yvals_binary = yvals.map({'screening stage cancer': 1, 'healthy': 0}) # Convert \"screening stage cancer\" to 1 and \"healthy\" to 0\n",
    "print(yvals_binary.unique()) # double confirm correct conversion of the y values \n",
    "logit_model = sm.Logit(yvals_binary, x_std) # carry out logistic regression\n",
    "result = logit_model.fit()\n",
    "print(result.summary()) # summary of model\n",
    "p_values = result.pvalues # obtain p values of regressor features in model\n",
    "significant_features_1 = list(p_values[p_values < 0.05].index.tolist()) # Filter out significant features with p-value < 0.05\n",
    "insignificant_features_1 = list(p_values[p_values > 0.05].index.tolist()) # Filter out insignificant features with p-value > 0.05\n",
    "\n",
    "### Perform L1 (lasso) regularisation to logistic regression model to idenitify insignifcant regressors with coefficients zero\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg_l1 = LogisticRegression(penalty='l1', solver='liblinear')  # specify solver for L1 regularization\n",
    "log_reg_l1.fit(x_std, yvals_binary)  # train model\n",
    "significant_features_2 = list(xvals.columns[log_reg_l1.coef_[0] != 0]) # check if there are any signifcant features identified\n",
    "insignificant_features_2 = list(xvals.columns[log_reg_l1.coef_[0] == 0]) # identify insignifcant features\n",
    "\n",
    "### Perform principal component analysis to identify insignifcant regressors that contrivbute little to variance\n",
    "from sklearn.decomposition import PCA \n",
    "pca = PCA() # initialise PCA with default parameters\n",
    "x_pca = pca.fit_transform(x_std) # compute principal components and transforms data into new feature space\n",
    "explained_variance_ratio = pca.explained_variance_ratio_  # Get explained variance ratio for each component\n",
    "cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio) # sum computed variance for certain number of components\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cumulative_explained_variance_ratio) # plot cumulative explained variance ratio\n",
    "plt.grid(True) # add grid to the plot\n",
    "plt.show() # show graph\n",
    "\n",
    "chosen_num_components = 25  # plateu cannot be read accurately so limit x axis to [0,25] and plot again\n",
    "plt.plot(range(1, chosen_num_components + 1), cumulative_explained_variance_ratio[:chosen_num_components])\n",
    "plt.grid(True) # add grid to the plot\n",
    "plt.show() # plateu can be read \n",
    "\n",
    "chosen_num_components = 3 # there is little to no change in cumulative variance when more than 3 principal components are involved in calculations\n",
    "pca = PCA(n_components = chosen_num_components) # initialise new pca with no of components = 3\n",
    "x_pca = pca.fit_transform(x_std) # compute principal components and transforms data into new feature space\n",
    "\n",
    "original_features = xvals.columns # all features\n",
    "significant_feature_indices = np.where(cumulative_explained_variance_ratio <= 0.95)[0] # identify festures that are responsible for 95 oercent of variance\n",
    "significant_features_3 = list(original_features[significant_feature_indices])\n",
    "insignificant_feature_indices = np.where(cumulative_explained_variance_ratio > 0.95)[0]\n",
    "insignificant_features_3 = list(original_features[insignificant_feature_indices])\n",
    "\n",
    "### Perform correlation analysis to identify insignifcant regressors that are are highly correlated\n",
    "correlation_matrix = xvals.corr() # find correlation coefficients between each pair of variables\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool)) # mask to consider only the upper triangular matrix and ignore correlation between the same variable. Output is true and false\n",
    "correlation_matrix = correlation_matrix.mask(mask) # apply mask to correlation matrix\n",
    "significant_features_4 = list(xvals.columns)\n",
    "insignificant_features_4 = []\n",
    " \n",
    "for i in range(len(correlation_matrix.columns)): # Loop through the columnns\n",
    "    for j in range(i): # Loop through the rows\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:  # Adjust the threshold as needed. Set 0.8 here\n",
    "            colname_i = correlation_matrix.columns[i] # first compared feature\n",
    "            colname_j = correlation_matrix.columns[j] # second compared feature\n",
    "            if colname_i in significant_features_4:\n",
    "                significant_features_4.remove(colname_i) # update the significant features\n",
    "            if colname_i not in insignificant_features_4:\n",
    "                insignificant_features_4.append(colname_i) # update the siugnifcant features\n",
    "\n",
    "### Decide which features to remove\n",
    "\n",
    "### check lengths of features to be removed\n",
    "removables = {}\n",
    "for feature in insignificant_features_1:\n",
    "    if feature not in removables:\n",
    "        removables[feature] = 0\n",
    "    removables[feature] += 1\n",
    "\n",
    "for feature in insignificant_features_2:\n",
    "    if feature not in removables:\n",
    "        removables[feature] = 0\n",
    "    removables[feature] += 1\n",
    "\n",
    "for feature in insignificant_features_3:\n",
    "    if feature not in removables:\n",
    "        removables[feature] = 0\n",
    "    removables[feature] += 1\n",
    "\n",
    "for feature in insignificant_features_4:\n",
    "    if feature not in removables:\n",
    "        removables[feature] = 0\n",
    "    removables[feature] += 1\n",
    "\n",
    "len(xvals.columns) # no of features in\\ dataset \n",
    "\n",
    "drops_2 = []\n",
    "for feature in removables:\n",
    "    if removables[feature] >= 2:\n",
    "        drops_2.append(feature)\n",
    "len(drops_2) # 349 variables removed # 1 variables preserved\n",
    "\n",
    "drops_3 = []\n",
    "for feature in removables:\n",
    "    if removables[feature] >= 3:\n",
    "        drops_3.append(feature)\n",
    "len(drops_3) # 333 variables removed # 17 variables preserved\n",
    "\n",
    "drops_4 = []\n",
    "for feature in removables:\n",
    "    if removables[feature] >= 4:\n",
    "        drops_4.append(feature)\n",
    "len(drops_4) # 0 variables remnoved # 350 variables preserved \n",
    "\n",
    "### drops_3 selected to prevent underfitting or overfitting of the model\n",
    "xvals_filtered = xvals.drop(columns=drops_3)\n",
    "xvals_filtered.shape\n",
    "\n",
    "# xvals_filtered to be used as dependent variables used to build the model\n",
    "# yvals to be used as the response variable used to build the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technique to remove regressors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform logistic regression to identify insignifcant regressors based on p value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
